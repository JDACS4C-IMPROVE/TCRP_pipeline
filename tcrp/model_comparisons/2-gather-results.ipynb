{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9609bc1a-10ad-4e9d-ba23-d59a8ca4eed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "!echo $HOSTNAME\n",
    "\n",
    "import sys\n",
    "print('Python path: ', sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e06573-afc3-42dc-8d7f-9f356554bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e9ea46-fce0-4e65-988f-1386fa066887",
   "metadata": {},
   "outputs": [],
   "source": [
    "Parameter = namedtuple(\"Parameter\", ['hyperparameter_str', 'epoch', 'result', 'improvement'])\n",
    "Results = namedtuple(\"Results\", ['hyperparameter_str', 'epoch', 'result', 'improvement', 'performance']) # hack to include performance in the namedtuple\n",
    "\n",
    "def parse_log_path(filepath): \n",
    "    stem = filepath.stem\n",
    "    \n",
    "    array = stem.split(\"_\")\n",
    "    hyperparameter_str = '_'.join(array[-4:])\n",
    "\n",
    "    result = None\n",
    "    epoch = None\n",
    "    with open(filepath) as f:\n",
    "        for line in f.readlines(): \n",
    "            if line.startswith(\"Best loss meta training:\"): \n",
    "                result = line.split('[')[1].replace(']', '').strip()\n",
    "                result = [float(i) for i in result.split()]\n",
    "                \n",
    "            if line.startswith(\"epoch:\"): \n",
    "                epoch = int(line.split(':')[1].strip())\n",
    "                \n",
    "    \n",
    "    return Parameter(hyperparameter_str, epoch, result, result[-1] - result[0])\n",
    "\n",
    "def get_predictions(path): \n",
    "    path = Path(path)\n",
    "    data = []\n",
    "    \n",
    "    predict = np.load(path / \"zero_shot_predict.npy\")\n",
    "    actual = np.load(path / \"zero_shot_true.npy\")\n",
    "\n",
    "    x = np.hstack([predict, actual]).T\n",
    "    zero = np.corrcoef(x)[0,1]\n",
    "    \n",
    "    for sample in range(20): \n",
    "        ks = [zero]\n",
    "        for k in range(1, 11): \n",
    "            predict = np.load(path / f\"{k}_{sample}_shot_predict.npy\")\n",
    "            actual = np.load(path / f\"{k}_{sample}_shot_true.npy\")\n",
    "            \n",
    "            x = np.hstack([predict, actual]).T\n",
    "            x = np.corrcoef(x)[0,1]\n",
    "            \n",
    "            ks.append(x)\n",
    "        data.append(ks)\n",
    "        \n",
    "    return np.vstack(data)\n",
    "\n",
    "def parse_logs(log_directory): \n",
    "    results = []\n",
    "    log_path = Path(log_directory)\n",
    "        \n",
    "    for log in log_path.glob(\"*\"): \n",
    "        result = parse_log_path(log)\n",
    "        results.append(result)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2028a80a-5280-46a5-8cdb-e2a2cae98d5d",
   "metadata": {},
   "source": [
    "## Gathering all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1b6172-ab09-4412-acf8-2ccdd53fcd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2bfb32-97f3-4d90-b66c-ff188b2d6400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_performances(folders): \n",
    "    log_folder, predictions_folder = folders\n",
    "    print(log_folder)\n",
    "    \n",
    "    outer = {}\n",
    "    for tissue in log_folder.glob(\"*\"):        \n",
    "        tissue = tissue.stem\n",
    "        p = log_folder / tissue\n",
    "        \n",
    "        # Get all validation and test performance for each hyperpaameter tuned\n",
    "        all_results = []\n",
    "        params = parse_logs(p)\n",
    "        for param in params: \n",
    "            predictions = get_predictions(predictions_folder / tissue / param.hyperparameter_str / f'epochs_{param.epoch}')\n",
    "            results = Results(*param, predictions)\n",
    "            all_results.append(results)\n",
    "\n",
    "        outer[tissue] = all_results\n",
    "            \n",
    "    return outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f26651-ec4a-4472-874b-ea58f0e142d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_directory = Path(\"/cellar/users/shfong/projects/TCRP-refactored/tcrp-original/output/210726_complete-drug-run-v2/predictions\")\n",
    "logs_directory = Path(\"/cellar/users/shfong/projects/TCRP-refactored/tcrp-original/output/210726_complete-drug-run-v2/run-logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38984140-676c-4127-9bb1-bfa13d78f951",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "paths = []\n",
    "drugs = []\n",
    "for drug_path in predictions_directory.glob(\"*\"): \n",
    "    drug = drug_path.stem    \n",
    "    log_path = logs_directory / drug\n",
    "    paths.append((log_path, drug_path))\n",
    "    drugs.append(drug)\n",
    "    \n",
    "with Pool(64) as pool: \n",
    "    results = pool.map(get_all_performances, paths)\n",
    "    \n",
    "all_results = {d: r for d, r in zip(drugs, results)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c49b93-bf9d-4e8c-bbb4-bb8434b4cf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff22999-ee1d-41d5-b44b-c294c50ae1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tcrp-all-performance.pkl\", \"wb\") as f: \n",
    "    pickle.dump(all_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae1c41d-c87b-4984-bda5-05da6b66e8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "ls -alh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2415f42f-e472-4b2d-a948-8f2edb718a88",
   "metadata": {},
   "source": [
    "## Getting results based on best improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5e5f5f-e59c-4582-abff-8cf7546b4866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "output = {}\n",
    "failed_paths = []\n",
    "for drug in predictions_directory.glob(\"*\"): \n",
    "    print(drug)\n",
    "    drug = drug.stem\n",
    "    \n",
    "    output[drug] = {}\n",
    "    \n",
    "    directory = logs_directory / drug\n",
    "    for tissue in directory.glob(\"*\"): \n",
    "        tissue = tissue.stem\n",
    "        \n",
    "        p = directory / tissue\n",
    "        \n",
    "        try: \n",
    "            results = parse_logs(p)\n",
    "            param = sorted(results, key=lambda x: x.improvement)[-1]\n",
    "            predictions = get_predictions(predictions_directory / drug / tissue / param.hyperparameter_str / f'epochs_{param.epoch}').mean(axis=0)\n",
    "\n",
    "            output[drug][tissue] = predictions\n",
    "            \n",
    "        except KeyboardInterrupt: \n",
    "            raise KeyboardInterrupt\n",
    "        \n",
    "        except: # None for results\n",
    "            failed_paths.append(p)\n",
    "            print(f\"Path {p} failed!\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf017db-4a86-42eb-8768-463f2a6fa9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f63213a-ebdf-47b9-9559-41feff842f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b4488f-f931-4fc0-a8c8-f6e56bcc1013",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tcrp-performance.pkl\", \"wb\") as f: \n",
    "    pickle.dump(output, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16875f87-dee9-4b4a-8994-b44ed6c19992",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee8221f-7d81-4740-aa3f-5ae0098ddf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "for drug, inner in output.items(): \n",
    "    for tissue, p in inner.items(): \n",
    "        all_results.append(p)\n",
    "        \n",
    "all_results = np.vstack(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14961929-fd74-40e3-8bb7-e806dcd6f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.nanmedian(all_results, axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (decipher)",
   "language": "python",
   "name": "decipher"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
